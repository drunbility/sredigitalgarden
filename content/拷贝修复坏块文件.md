
1.  通过 hdfs 命令把 missing block 的文件列出到文件

hdfs fsck -Dfs.defaultFS=hdfs://HDFS84008 -list-corruptfileblocks | awk '{print $2}' > files.list

2.  通过批量重新拷贝文件来修复 missing block  

nohup /bin/sh /data/qy/ca_alg/history_copy/history_copy.sh /data/qy/ca_alg/history_copy/files.list &

3.  等待文件拷贝完成,missing block 告警消失后,可再次验证拷贝文件 checksum

nohup /bin/sh /data/qy/ca_alg/history_copy/checksum.sh /data/qy/ca_alg/history_copy/files.list &



history_cocy.sh:

```
#!/bin/bash

  
  

if [ ! -n "$1" ] ;then

echo "you have not input a file!"

else

echo "the word you input is $1"

fi

  

dataline=$(cat $1)

var=$1

var=${var//,/ } #这里是将var中的,替换为空格

source=hdfs://nn03.pkx01.rack.xxxxx.com:xxxx

target=hdfs://HDFS84008

runningnum=10

export HADOOP_USER_NAME=hadoop

export HADOOP_USER_PASSWORD=tx_xxxxxxx

num=0

  

for line in $dataline

do

  

num=$[$num+1]

echo $source$line

echo $target$line

echo $num

task_name=`echo $line | awk -F"/" '{print $NF}'`

echo $task_name

runningapp=$(ps -ef | grep distcp |wc -l)

echo "runningapp:"$runningapp

  

while [ $runningapp -ge $runningnum ]

do

runningapp=$(ps -ef | grep distcp |wc -l)

echo "正在执行的任务数："$runningapp",sleep 1秒...."

sleep 1

done

nohup hadoop distcp -D mapreduce.job.queuename=r7_distcp -Dmapreduce.job.name=$task_name -Ddfs.checksum.combine.mode=COMPOSITE_CRC -Dfs.gs.checksum.type=CRC32C -Dfs.defaultFS=hdfs://HDFS84008 -Dmapreduce.map.memory.mb=4096 -pbugpt -i -strategy dynamic -overwrite -numListstatusThreads 31 -bandwidth 100 -m 400 $source$line $target$line > /data/qy/ca_alg/history_copy/lide/logs/$task_name.log 2>&1 &

  

sleep 0.1

  
  

#cd "$(dirname "$0")"

#str=`date +%Y%m%d%H%M%S`

done

  

wait

```

checksum.sh:

```
#!/bin/bash


if [ ! -n "$1" ] ;then
    echo "you have not input a file!"
else
    echo "the word you input is $1"
fi

dataline=$(cat $1)
var=$1
var=${var//,/ } #这里是将var中的,替换为空格
source=hdfs://nn03.pkx01.rack.xxxxx.com:xxxx
target=hdfs://HDFS84008
runningnum=10
export HADOOP_USER_NAME=hadoop
export HADOOP_USER_PASSWORD=tx_xxxx
num=0

for line in $dataline
do

    num=$[$num+1]
    echo $source$line
    echo $target$line
    echo $num
    task_name=`echo $line | awk -F"/" '{print $NF}'`
    echo $task_name    
    runningapp=$(ps -ef | grep distcp |wc -l)
    echo "runningapp:"$runningapp

    while [ $runningapp -ge $runningnum ]
    do
      runningapp=$(ps -ef | grep distcp |wc -l)
      echo "正在执行的任务数："$runningapp",sleep 1秒...."
      sleep 1
    done
    source_checksum=$(hadoop fs -D mapreduce.job.queuename=r7_distcp -Ddfs.checksum.combine.mode=COMPOSITE_CRC -checksum $source$line | awk '{print $3}')
    target_checksum=$(hadoop fs -D mapreduce.job.queuename=r7_distcp -Ddfs.checksum.combine.mode=COMPOSITE_CRC -checksum $target$line | awk '{print $3}')
    echo "source checksum: " ${source_checksum}
    echo "target checksum: " ${target_checksum}
    if [ ${source_checksum} != ${target_checksum} ]; then
       echo "ERROR: checksum failed in $line"
    fi

sleep 0.1


      
   #cd "$(dirname "$0")"
    #str=`date +%Y%m%d%H%M%S`
done

wait


```