#### 背景: 

节假日期间数据任务在凌晨时期出现较大任务堆积，业务侧出数压力较大，平台侧只能通过轮班手动移动队列来消化堆积


#### 原因:

大数据平台侧在提交 Spark 任务的时候,将 executor cores 和 memory 配置写死了, yarn 分出去了较多资源,但实际上很多任务是在空跑,本身物理资源占用并没有那么大.


#### 成效：

当时分析了 yarn 和 集群监控后，通过对 yarn 集群进行资源的超配来解决这个问题。超配后，数据任务凌晨堆积问题有较大缓解
    
#### 优化:

在对集群的资源监控进行观测中，发现集群的资料利用率有一个很高的高峰期，也就是凌晨后。但如果把观测时间拉长，看集群的平均利用率，并不是很高。对于这张问题两种解决方案：

- 削峰平谷 这个变更数据任务的调度时间，对业务有较大改动，需要业务侧配合

- 弹性扩缩容 也就是 Elastic MapReduce 。可以使用混合云的方式，就是只在云上扩缩容计算资源。数据还是保存在本地机房

 - [Hadoop YARN降本增效之动态超卖技术 (qq.com)](https://mp.weixin.qq.com/s/V7PrYQIrNrgKSHpRRACpCA)



